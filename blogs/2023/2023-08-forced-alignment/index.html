<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="An intuitive explanation of forced alignment with Viterbi decoding."><meta name=author content="['Elena Rastorgueva']"><link href=https://nvidia.github.io/NeMo/blogs/2023/2023-08-forced-alignment/ rel=canonical><link href=../2023-08-nfa/ rel=prev><link href=../2023-10-28-numba-fp16/ rel=next><link rel=icon href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.6"><title>How does forced alignment work? - NVIDIA NeMo</title><link rel=stylesheet href=../../../assets/stylesheets/main.50c56a3b.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><!-- Add scripts that need to run before here --><!-- Add scripts that need to run afterward here --><!-- Add Twitter Card metadata --><meta name=twitter:card content=summary_large_image><!-- Add OpenGraph Title metadata --><meta property=og:title content="How does forced alignment work?"><meta name=twitter:title content="How does forced alignment work?"><!-- Add OpenGraph Type metadata --><meta property=og:type content=website><!-- Add OpenGraph URL metadata --><meta content=https://nvidia.github.io/NeMo/blogs/2023/2023-08-forced-alignment/ property=og:url><!-- Add OpenGraph Image metadata --><meta property=og:image content=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-ctc_trellis.png><meta property=twitter:image content=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-ctc_trellis.png><!-- Add OpenGraph Image Type metadata --><meta property=og:image:type content=image/png><!-- Add OpenGraph Description metadata --><meta property=og:description content="An intuitive explanation of forced alignment with Viterbi decoding."><meta property=twitter:description content="An intuitive explanation of forced alignment with Viterbi decoding."></head> <body dir=ltr data-md-color-scheme=midnight-black data-md-color-primary=indigo data-md-color-accent=light-blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#how-does-forced-alignment-work class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="NVIDIA NeMo" class="md-header__button md-logo" aria-label="NVIDIA NeMo" data-md-component=logo> <svg id=Layer_1 data-name="Layer 1" xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"> <defs> <style>
      .cls-1 {
        fill: #76b900;
      }
    </style> </defs> <g id=NVIDIA_Logo data-name="NVIDIA Logo"> <path id=Eye_Mark class=cls-1 d=M5.9698,5.86543V4.90907c.09285-.00661.18663-.01156.28219-.01456A5.75152,5.75152,0,0,1,10.58372,7.142S8.73032,9.71631,6.74309,9.71631a2.40975,2.40975,0,0,1-.77329-.12364v-2.9c1.01832.123,1.223.57279,1.83539,1.59325l1.36157-1.148A3.60517,3.60517,0,0,0,6.49742,5.83431a4.93745,4.93745,0,0,0-.52762.03112m0-3.15922V4.13474c.09389-.00742.1879-.0134.28219-.0168,3.63754-.12254,6.0073,2.98317,6.0073,2.98317s-2.722,3.31-5.55774,3.31a4.18488,4.18488,0,0,1-.73175-.06444v.883a4.81728,4.81728,0,0,0,.60938.03947c2.639,0,4.54736-1.34759,6.39542-2.94267.30618.24532,1.56062.8421,1.8186,1.1037-1.75722,1.47088-5.852,2.65644-8.17346,2.65644-.22369,0-.43886-.01352-.64994-.03376v1.241H16V2.70621Zm0,6.88646v.754A4.26109,4.26109,0,0,1,2.85159,7.37428,5.27645,5.27645,0,0,1,5.9698,5.86543v.8272l-.0038-.0004a2.34214,2.34214,0,0,0-1.81935.83163A3.25091,3.25091,0,0,0,5.9698,9.59267M1.63473,7.26433A6.045,6.045,0,0,1,5.9698,4.90907V4.13474C2.77053,4.39151,0,7.10111,0,7.10111s1.56908,4.53638,5.9698,4.95171v-.82318C2.74044,10.82334,1.63473,7.26433,1.63473,7.26433Z data-name="Eye Mark"/> </g> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> NVIDIA NeMo </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> How does forced alignment work? </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=midnight-black data-md-color-primary=indigo data-md-color-accent=light-blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=light-blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/NVIDIA/NeMo title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> NVIDIA/NeMo </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../../../publications/ class=md-tabs__link> Publications </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="NVIDIA NeMo" class="md-nav__button md-logo" aria-label="NVIDIA NeMo" data-md-component=logo> <svg id=Layer_1 data-name="Layer 1" xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"> <defs> <style>
      .cls-1 {
        fill: #76b900;
      }
    </style> </defs> <g id=NVIDIA_Logo data-name="NVIDIA Logo"> <path id=Eye_Mark class=cls-1 d=M5.9698,5.86543V4.90907c.09285-.00661.18663-.01156.28219-.01456A5.75152,5.75152,0,0,1,10.58372,7.142S8.73032,9.71631,6.74309,9.71631a2.40975,2.40975,0,0,1-.77329-.12364v-2.9c1.01832.123,1.223.57279,1.83539,1.59325l1.36157-1.148A3.60517,3.60517,0,0,0,6.49742,5.83431a4.93745,4.93745,0,0,0-.52762.03112m0-3.15922V4.13474c.09389-.00742.1879-.0134.28219-.0168,3.63754-.12254,6.0073,2.98317,6.0073,2.98317s-2.722,3.31-5.55774,3.31a4.18488,4.18488,0,0,1-.73175-.06444v.883a4.81728,4.81728,0,0,0,.60938.03947c2.639,0,4.54736-1.34759,6.39542-2.94267.30618.24532,1.56062.8421,1.8186,1.1037-1.75722,1.47088-5.852,2.65644-8.17346,2.65644-.22369,0-.43886-.01352-.64994-.03376v1.241H16V2.70621Zm0,6.88646v.754A4.26109,4.26109,0,0,1,2.85159,7.37428,5.27645,5.27645,0,0,1,5.9698,5.86543v.8272l-.0038-.0004a2.34214,2.34214,0,0,0-1.81935.83163A3.25091,3.25091,0,0,0,5.9698,9.59267M1.63473,7.26433A6.045,6.045,0,0,1,5.9698,4.90907V4.13474C2.77053,4.39151,0,7.10111,0,7.10111s1.56908,4.53638,5.9698,4.95171v-.82318C2.74044,10.82334,1.63473,7.26433,1.63473,7.26433Z data-name="Eye Mark"/> </g> </svg> </a> NVIDIA NeMo </label> <div class=md-nav__source> <a href=https://github.com/NVIDIA/NeMo title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> NVIDIA/NeMo </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> <li class=md-nav__item> <a href=../../archive/2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../category/announcements/ class=md-nav__link> <span class=md-ellipsis> Announcements </span> </a> </li> <li class=md-nav__item> <a href=../../category/nvidia-technical-blog/ class=md-nav__link> <span class=md-ellipsis> NVIDIA Technical blog </span> </a> </li> <li class=md-nav__item> <a href=../../category/papers/ class=md-nav__link> <span class=md-ellipsis> Papers </span> </a> </li> <li class=md-nav__item> <a href=../../category/technical-deep-dive/ class=md-nav__link> <span class=md-ellipsis> Technical deep-dive </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../../publications/ class="md-nav__link "> <span class=md-ellipsis> Publications </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Publications </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../publications/archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/archive/2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/archive/2021/ class=md-nav__link> <span class=md-ellipsis> 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/archive/2020/ class=md-nav__link> <span class=md-ellipsis> 2020 </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/archive/2019/ class=md-nav__link> <span class=md-ellipsis> 2019 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../publications/category/inverse-text-normalization/ class=md-nav__link> <span class=md-ellipsis> (Inverse) Text Normalization </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/automatic-speech-recognition/ class=md-nav__link> <span class=md-ellipsis> Automatic Speech Recognition </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/dialog-state-tracking/ class=md-nav__link> <span class=md-ellipsis> Dialog State Tracking </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/large-language-models/ class=md-nav__link> <span class=md-ellipsis> Large Language Models </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/natural-language-processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/neural-machine-translation/ class=md-nav__link> <span class=md-ellipsis> Neural Machine Translation </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/speaker-recognition/ class=md-nav__link> <span class=md-ellipsis> Speaker Recognition </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/speech-classification/ class=md-nav__link> <span class=md-ellipsis> Speech Classification </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/speech-translation/ class=md-nav__link> <span class=md-ellipsis> Speech Translation </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/text-to-speech/ class=md-nav__link> <span class=md-ellipsis> Text to Speech </span> </a> </li> <li class=md-nav__item> <a href=../../../publications/category/tools/ class=md-nav__link> <span class=md-ellipsis> Tools </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#what-is-forced-alignment class=md-nav__link> <span class=md-ellipsis> What is forced alignment? </span> </a> </li> <li class=md-nav__item> <a href=#formulating-the-problem class=md-nav__link> <span class=md-ellipsis> Formulating the problem </span> </a> </li> <li class=md-nav__item> <a href=#forced-alignment-the-naive-way class=md-nav__link> <span class=md-ellipsis> Forced alignment the naive way </span> </a> </li> <li class=md-nav__item> <a href=#the-naive-way-but-listing-all-the-possible-paths-using-a-graph class=md-nav__link> <span class=md-ellipsis> The naive way but listing all the possible paths using a graph </span> </a> </li> <li class=md-nav__item> <a href=#the-trouble-with-longer-sequences class=md-nav__link> <span class=md-ellipsis> The trouble with longer sequences </span> </a> </li> <li class=md-nav__item> <a href=#spotting-graph-redundancies class=md-nav__link> <span class=md-ellipsis> Spotting graph redundancies </span> </a> </li> <li class=md-nav__item> <a href=#formalizing-the-efficient-forced-alignment-algorithm class=md-nav__link> <span class=md-ellipsis> Formalizing the efficient forced alignment algorithm </span> </a> </li> <li class=md-nav__item> <a href=#the-viterbi-algorithm class=md-nav__link> <span class=md-ellipsis> The Viterbi algorithm </span> </a> </li> <li class=md-nav__item> <a href=#extending-to-ctc class=md-nav__link> <span class=md-ellipsis> Extending to CTC </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <!-- Edit button --> <a href=https://github.com/NVIDIA/NeMo/edit/master/docs/blogs/posts/2023/2023-08-forced-alignment.md title=edit.link.title class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg> </a> <!-- Back to index button --> <!-- Note: using "align-items:center" to make sure that the arrow looks vertically centered relative to the text --> <a href=../../ class=" md-nav__link" style="align-items:center; color: var(--md-default-fg-color--light); padding-bottom:20px; font-weight: 700;"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> <span class=md-ellipsis> Back to index </span> </a> <!-- Blogging Markup --> <!--        <p class="p-blog">--> <!--        <img src="https://avatars.githubusercontent.com/" alt="@">--> <!--        </p>--> <!--        <p class="p-blog">--> <!-- If number of authors of less than 3, put on new lines --> <aside class=mdx-author> <!-- Add author name --> <span class=post-author> <b>Elena Rastorgueva</b> <!-- Add author GitHub link if 1:1 map exists between author names and author gh ids --> · <a href=https://github.com/erastorgueva-nv>@erastorgueva-nv</a> <!-- Add comma if not last author --> </span> <!-- If number of authors is less than 3, put on new lines --> </aside> <p class=p-blog> <span> <!-- Note: using "margin-bottom:-2px" to make sure icons look more-or-less vertically centered relative to the text --> <svg style=margin-bottom:-2px; xmlns=http://www.w3.org/2000/svg width=16 height=16 fill=currentColor class="bi bi-calendar2" viewbox="0 0 16 16"> <path d="M3.5 0a.5.5 0 0 1 .5.5V1h8V.5a.5.5 0 0 1 1 0V1h1a2 2 0 0 1 2 2v11a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V3a2 2 0 0 1 2-2h1V.5a.5.5 0 0 1 .5-.5zM2 2a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H2z"/> <path d="M2.5 4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5H3a.5.5 0 0 1-.5-.5V4z"/> </svg> 2023-08-14 · <svg style=margin-bottom:-2px; xmlns=http://www.w3.org/2000/svg width=16 height=16 fill=currentColor class="bi bi-clock" viewbox="0 0 16 16"> <path d="M8 3.5a.5.5 0 0 0-1 0V9a.5.5 0 0 0 .252.434l3.5 2a.5.5 0 0 0 .496-.868L8 8.71V3.5z"/> <path d="M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm7-8A7 7 0 1 1 1 8a7 7 0 0 1 14 0z"/> </svg> 15 minute read </span> </p> <!-- Markdown content --> <h1 id=how-does-forced-alignment-work>How does forced alignment work?<a class=headerlink href=#how-does-forced-alignment-work title="Permanent link">&para;</a></h1> <p>In this blog post we will explain how you can use an Automatic Speech Recognition (ASR) model<sup id=fnref:1><a class=footnote-ref href=#fn:1>1</a></sup> to match up the text spoken in an audio file with the time when it is spoken. Once you have this information, you can do downstream tasks such as:</p> <ul> <li> <p>creating subtitles such as in the video below<sup id=fnref:butter_betty_bought><a class=footnote-ref href=#fn:butter_betty_bought>2</a></sup> or in the Hugging Face <a href=https://huggingface.co/spaces/erastorgueva-nv/NeMo-Forced-Aligner>space</a></p> </li> <li> <p>obtaining durations of tokens or words to use in <a href=https://arxiv.org/pdf/2104.08189.pdf>Text To Speech</a> or speaker diarization models</p> </li> <li> <p>splitting long audio files (and their transcripts) into shorter ones. This is especially useful when making datasets for training new ASR models, since audio files that are too long will not be able to fit onto a single GPU during training. <sup id=fnref:2><a class=footnote-ref href=#fn:2>3</a></sup></p> </li> </ul> <!-- more --> <figure> <p><div class=video-container><video style="position: relative; width: 100%; height: 22.172vw" controls><source src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-butter_betty_bought_words_aligned.mp4 type=video/mp4></video></div> </p> <figcaption>Video with words highlighted according to timestamps obtained with NFA</figcaption> </figure> <h2 id=what-is-forced-alignment>What is forced alignment?<a class=headerlink href=#what-is-forced-alignment title="Permanent link">&para;</a></h2> <p>This task of matching up text to when it is spoken is called 'forced alignment'. We use 'best alignment', 'most likely alignment' or sometimes just 'the alignment' to refer to the most likely link between the text and where in the audio it is spoken. Normally these links are between chunks of the audio and the text tokens<sup id=fnref:3><a class=footnote-ref href=#fn:3>4</a></sup>. If we are interested in word alignments, we can simply group together the token alignments for each word.</p> <figure> <p><img alt="What is alignment" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-what_is_alignment.png> </p> <figcaption>Diagram of a possible alignment between audio with 5 timesteps and text with 3 tokens ('C', 'A', 'T')</figcaption> </figure> <p>The 'forced' in 'forced alignment' refers to the fact that we provide the reference text ourselves and use the ASR model to get an alignment based on the assumption that this reference text is the real ground truth, i.e. exactly what is spoken - sometimes it makes sense to drop this requirement in case your reference text is incorrect. There are various other aligners that work on this assumption<sup id=fnref:5><a class=footnote-ref href=#fn:5>5</a></sup>.</p> <p>Sometimes in discussing this topic, we may drop the 'forced' and just call it 'alignment' when we mean 'forced alignment'. We will sometimes do this in this tutorial, for brevity.</p> <figure class="inline end"> <p><!--doing class="inline end" as a way to get around the fact that without it, the image will be off-center if we specify its width--> <img alt="Alignment as token duplication" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-alignment_slots.png width=400> </p> <figcaption>We can think of an alignment as a way to arrange the S number of tokens into T number of boxes</figcaption> </figure> <p>In forced alignment our two inputs are the audio and the text. You can think of the audio as being split into <span class=arithmatex>\(T\)</span> equally-sized chunks, or 'timesteps', and the text as being a sequence of <span class=arithmatex>\(S\)</span> tokens. So we can think of an alignment as either a mapping from the <span class=arithmatex>\(S\)</span> tokens to the <span class=arithmatex>\(T\)</span> timesteps, or as a way of duplicating some of the tokens so that we have a sequence of <span class=arithmatex>\(T\)</span> of them, each being mapped to the timestep when it is spoken. Thus this alignment algorithm will only work if <span class=arithmatex>\(T \ge S\)</span>.</p> <p>The task of forced alignment is basically figuring out what the exact <span class=arithmatex>\(T\)</span>-length sequence of these tokens should be in order to give you the best alignment.</p> <h2 id=formulating-the-problem>Formulating the problem<a class=headerlink href=#formulating-the-problem title="Permanent link">&para;</a></h2> <p>To do forced alignment, we will need an already-trained ASR model <sup id=fnref:7><a class=footnote-ref href=#fn:7>6</a></sup>. This model's input is the spectrogram of an audio file, which is a representation of the frequencies present in the audio signal. The spectrogram will have <span class=arithmatex>\(T_{in}\)</span> timesteps. The ASR model will output a probability matrix of size <span class=arithmatex>\(V \times T\)</span> where <span class=arithmatex>\(V\)</span> is the number of tokens in our vocabulary (e.g. the number of letters in the alphabet of the language we are transcribing) and <span class=arithmatex>\(T\)</span> is the number of output timesteps. <span class=arithmatex>\(T\)</span> may be equal to <span class=arithmatex>\(T_{in}\)</span>, or it may be smaller by some ratio if our ASR model has some downsampling in its neural net architecture. For example, NeMo's pretrained models have the following downsampling ratios:</p> <ul> <li>NeMo <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html#quartznet>QuartzNet</a> models have <span class=arithmatex>\(T = \frac{T_{in}}{2}\)</span></li> <li>NeMo <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html#conformer-ctc>Conformer</a> models have <span class=arithmatex>\(T = \frac{T_{in}}{4}\)</span></li> <li>NeMo <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html#citrinet>Citrinet</a> and <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html#fast-conformer>FastConformer</a> models have <span class=arithmatex>\(T = \frac{T_{in}}{8}\)</span></li> </ul> <p>In the diagram below, we have drawn <span class=arithmatex>\(T_{in} = 40\)</span> and <span class=arithmatex>\(T = 5\)</span>, as one would obtain from one of the pretrained NeMo Citrinet or FastConformer models, which have a downsampling ratio of 8. In terms of seconds, as spectrogram frames are 0.01 seconds apart, each column in the spectrogram corresponds to 0.01 seconds, and each column in the ASR Model output matrix corresponds to <span class=arithmatex>\(0.01 \times 8 = 0.08\)</span> seconds.</p> <figure> <p><img alt="ASR model diagram" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-asr_model.png width=450> </p> <figcaption>The input audio contains T_{in} timesteps. The matrix outputted by the ASR Model has shape V x T</figcaption> </figure> <p>As mentioned above, the ASR Model's output matrix is of size <span class=arithmatex>\(V \times T\)</span>. The number found in row <span class=arithmatex>\(v\)</span> of column <span class=arithmatex>\(t\)</span> of this matrix is the probability that the <span class=arithmatex>\(v\)</span>-th token is being spoken at timestep <span class=arithmatex>\(t\)</span>. Thus, all the numbers in a given column must add up to 1.</p> <p>If we didn't know anything about what is spoken in the audio, we would need to "decode" this output matrix to produce the best possible transcription. That is a whole research area of its own - a topic for another day.</p> <p>Our task is <strong>forced alignment</strong>, where by definition we have some reference text matching the ground truth text that is actually spoken (e.g. "cat") and we want to specify exactly when each token is spoken.</p> <p>As mentioned in the previous section, we essentially have <span class=arithmatex>\(T\)</span> slots, and we want to fill each slot with the tokens <code>'C', 'A', 'T'</code> (in that order) in the locations where the sound of each token is spoken.</p> <p>To make sure we go through the letters in order, we can think of this <span class=arithmatex>\(T\)</span>-length sequence as being one which passes through the graph below from start to finish, making a total of <span class=arithmatex>\(T\)</span> stops on the red tokens.</p> <figure> <p><img alt="Allowed token sequence" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-alowed_seq.png> </p> <figcaption>Every possible alignment passes from "START" to "END" with T stops at each red token</figcaption> </figure> <p>For now we ignore the possibility of some of the audio not containing any speech and the possibility of a 'blank' token, which is a key feature of CTC ("Connectionist Temporal Classification") models — we will get to that <a href=#extending-to-ctc>later</a>.</p> <p>Let's look at the (made-up) output of our ASR model. We've removed all the tokens from our vocabulary except <code>CAT</code> and normalized the columns to make the maths easier for our example. We denote the values in this matrix as <span class=arithmatex>\(p(s,t)\)</span>, where <span class=arithmatex>\(s\)</span> is the index of the token in the ground truth, and <span class=arithmatex>\(t\)</span> is the timestep in the audio.</p> <table style='\"margin-left:' 0 !important;&quot;\> <tr> <th>Timestep:</th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> </tr> <tr> <td>C</td> <td>0.7</td> <td>0.4</td> <td>0.1</td> <td>0.1</td> <td>0.1</td> </tr> <tr> <td>A</td> <td>0.1</td> <td>0.3</td> <td>0.2</td> <td>0.4</td> <td>0.2</td> </tr> <tr> <td>T</td> <td>0.2</td> <td>0.3</td> <td>0.7</td> <td>0.5</td> <td>0.7</td> </tr> </table> <p>Our first instinct may be to try to take the argmax of each column in <span class=arithmatex>\(p(s,t)\)</span>, however that may lead to an alignment which does not match the order of tokens in the reference text, or may leave out some tokens entirely. In the current example, such a strategy will yield <code>C (0.7) -&gt; C (0.4) -&gt; T (0.7) -&gt; T (0.5) -&gt; T (0.5)</code>, which spells <code>CT</code> instead of <code>CAT</code>.</p> <h2 id=forced-alignment-the-naive-way>Forced alignment the naive way<a class=headerlink href=#forced-alignment-the-naive-way title="Permanent link">&para;</a></h2> <p>The issue with the above attempt is we did not restrict our search to only alignments that would spell out <code>CAT</code>.</p> <p>Since our number of timesteps (<span class=arithmatex>\(T=5\)</span>) and tokens (<span class=arithmatex>\(S=3\)</span>) is small, we can list out every possible alignment, i.e. every possible arrangement of <code>'CAT'</code> that will fit in our 5 slots:</p> <table style='\"margin-left:' 0 !important;&quot;\> <tr> <th>Timestep:</th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> </tr> <tr> <td>alignment 1</td> <td>C</td> <td>C</td> <td>C</td> <td>A</td> <td>T</td> </tr> <tr> <td>alignment 2</td> <td>C</td> <td>C</td> <td>A</td> <td>A</td> <td>T</td> </tr> <tr> <td>alignment 3</td> <td>C</td> <td>C</td> <td>A</td> <td>T</td> <td>T</td> </tr> <tr> <td>alignment 4</td> <td>C</td> <td>A</td> <td>A</td> <td>A</td> <td>T</td> </tr> <tr> <td>alignment 5</td> <td>C</td> <td>A</td> <td>A</td> <td>T</td> <td>T</td> </tr> <tr> <td>alignment 6</td> <td>C</td> <td>A</td> <td>T</td> <td>T</td> <td>T</td> </tr> </table> <p>Each token has a certain probability of being spoken at each time step, determined by our ASR model. The probability of a particular sequence of tokens is calculated by multiplying together the individual probabilities of each token at each timestep. Assuming our ASR model is a good one, the best alignment is the one with the highest cumulative probability.</p> <p>Let's show the <span class=arithmatex>\(p(s,t)\)</span> probabilities again.</p> <table style='\"margin-left:' 0 !important;&quot;\> <tr> <th>Timestep:</th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> </tr> <tr> <td>C</td> <td>0.7</td> <td>0.4</td> <td>0.1</td> <td>0.1</td> <td>0.1</td> </tr> <tr> <td>A</td> <td>0.1</td> <td>0.3</td> <td>0.2</td> <td>0.4</td> <td>0.2</td> </tr> <tr> <td>T</td> <td>0.2</td> <td>0.3</td> <td>0.7</td> <td>0.5</td> <td>0.7</td> </tr> </table> <p>We can calculate the probability of each possible alignment by multiplying together each <span class=arithmatex>\(p(s,t)\)</span> that it passes through:</p> <table style='\"margin-left:' 0 !important;&quot;\> <tr> <th>Timestep:</th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> <th>Total probability of alignment</th> </tr> <tr> <td>alignment 1</td> <td>C</td> <td>C</td> <td>C</td> <td>A</td> <td>T</td><td>0.7 * 0.4 * 0.1 * 0.4 * 0.7 = 0.008</td> </tr> <tr> <td>alignment 2</td> <td>C</td> <td>C</td> <td>A</td> <td>A</td> <td>T</td> <td>0.7 * 0.4 * 0.2 * 0.4 * 0.7 = 0.016</td> </tr> <tr> <td>alignment 3</td> <td>C</td> <td>C</td> <td>A</td> <td>T</td> <td>T</td><td>0.7 * 0.4 * 0.2 * 0.5 * 0.7 = 0.020</td> </tr> <tr> <td>alignment 4</td> <td>C</td> <td>A</td> <td>A</td> <td>A</td> <td>T</td><td>0.7 * 0.3 * 0.2 * 0.4 * 0.7 = 0.012 </td> </tr> <tr> <td>alignment 5</td> <td>C</td> <td>A</td> <td>A</td> <td>T</td> <td>T</td><td>0.7 * 0.3 * 0.2 * 0.5 * 0.7 = 0.015</td> </tr> <tr> <td>alignment 6</td> <td>C</td> <td>A</td> <td>T</td> <td>T</td> <td>T</td><td>0.7 * 0.3 * 0.7 * 0.5 * 0.7 = 0.051 <- the max</td> </tr> </table> <p>We can see that the most likely path is <code>'CATTT'</code> because it has the highest total probability. In other words, based on our ASR model, the most likely alignment is that <code>'C'</code> was spoken at the first timestep, <code>'A'</code> was spoken at the second timestep, and <code>'T'</code> was spoken for the last 3 timesteps. </p> <h2 id=the-naive-way-but-listing-all-the-possible-paths-using-a-graph>The naive way but listing all the possible paths using a graph<a class=headerlink href=#the-naive-way-but-listing-all-the-possible-paths-using-a-graph title="Permanent link">&para;</a></h2> <p>To make further progress in understanding forced alignment, let's list all the possible paths in a systematic way by arranging them in a tree-like graph like the one below. </p> <p>We initialize the graph with a 'start' node (for clarity), then connect it to nodes representing the tokens that our alignment can have at the first timestep (<code>t=1</code>). In our case, this is only a single token <code>C</code>. From that <code>C</code> node, we draw arrows to 2 other nodes. The higher node represents staying at the same token (<code>C</code>) for the next timestep (<code>t=2</code>). The lower node represents going to the next token (<code>A</code>) for the next timestep (<code>t=2</code>). We continue this process until we have drawn all the possible paths through our reference text tokens for the fixed duration <span class=arithmatex>\(T\)</span>. We do not include paths that reach the final token too early or too late.</p> <p>We end up with the tree below, which represents all the possible paths through the <code>CAT</code> tokens over 5 timesteps. </p> <p>You can check for yourself that every alignment we listed in the table in the previous section is represented as a path from left to right in this tree.</p> <p>We can label each node in the graph with its <span class=arithmatex>\(p(s,t)\)</span> probabilities (dark green).</p> <p>Let's also calculate the cumulative product along each path and include that as well (light green).</p> <p>Once we do that, we can look at all the nodes at the final timestep, and see that the cumulative product at each node is the cumulative probability of the path from start to T that lands at that node. </p> <p>As before, we can see that the probability of the most likely path, i.e. the most likely alignment, is 0.051. If we trace back our steps from that T node to the start, then we see that the path is <code>'CATTT'</code>.<sup id=fnref:greedy_path><a class=footnote-ref href=#fn:greedy_path>7</a></sup></p> <figure> <p><div class=video-container><video style="position: relative; width: 100%; height: 22.172vw" controls><source src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-naive_graph.mp4 type=video/mp4></video></div> </p> <figcaption>This graph lists every possible alignment. The most likely alignment becomes highlighted in purple.</figcaption> </figure> <h2 id=the-trouble-with-longer-sequences>The trouble with longer sequences<a class=headerlink href=#the-trouble-with-longer-sequences title="Permanent link">&para;</a></h2> <p>The naive method in the previous sections was intuitive, easy to calculate and gave us the correct answer, but it was only feasible because we had such a small number of possible alignments. In an utterance of 10 words over 5 seconds, conservatively you can expect 20 tokens and 63 timesteps<sup id=fnref:tokens_timesteps><a class=footnote-ref href=#fn:tokens_timesteps>8</a></sup> - that would lead to about <span class=arithmatex>\(4.8 \times 10^{15}\)</span> possible alignments<sup id=fnref:stars_bars><a class=footnote-ref href=#fn:stars_bars>9</a></sup>! </p> <p>Fortunately there is a method to obtain the most likely alignment, for which you:</p> <ul> <li>don't need to calculate all the cumulative products for every path, and</li> <li>don't even need to draw the full tree graph.</li> </ul> <p>We will work towards this method in the next sections.</p> <h2 id=spotting-graph-redundancies>Spotting graph redundancies<a class=headerlink href=#spotting-graph-redundancies title="Permanent link">&para;</a></h2> <p>Fortunately, because we are only interested in the highest probability path from the start node to one of the final <code>T</code> nodes on the right, this means that the tree graph has a lot of redundant nodes that we don't need to worry about.</p> <p>For example, consider the two nodes in the tree corresponding to token <code>A</code> (<code>s=2</code>) at time <code>t=3</code>. Looking at the cumulative products of these two nodes (in light green), we can see that the top <code>A</code> node (corresponding to the partial path <code>CCA</code>) has a cumulative product of 0.056, while the bottom <code>A</code> node (corresponding to the partial path <code>CAA</code>) has a smaller cumulative product of 0.042.</p> <p>The paths downstream of the top node are identical in graph structure to those downstream of the bottom node, as are the <span class=arithmatex>\(p(s,t)\)</span> values (in dark green) of any nodes in these downstream paths. Therefore, since the cumulative product of any path downstream of an <code>A</code> node at <code>t=3</code> will just be the cumulative product of that <code>A</code> node at <code>t=3</code> multiplied by these downstream <span class=arithmatex>\(p(s,t)\)</span> values, it is impossible for any path downstream of the bottom <code>A</code> node to have a higher cumulative product than the corresponding path downstream of the top <code>A</code> node. Thus, it is impossible that any of the paths downstream of the bottom <code>A</code> node will end up being the optimal path overall, and we can safely discard them. This is shown in the animation below.</p> <figure> <p><div class=video-container><video style="position: relative; width: 100%; height: 22.172vw" controls><source src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-redundancy_explain.mp4 type=video/mp4></video></div> </p> <figcaption>If we examine the two 'A' nodes at 't=3', we see that we can discard the node with the lower cumulative product, and the nodes downstream of it.</figcaption> </figure> <p>These redundancies exist between any nodes with the same <span class=arithmatex>\(s\)</span> and <span class=arithmatex>\(t\)</span> values. All of their downstream nodes will have the same structure, but we only need to keep the node that corresponds to the <strong>most probable path</strong> from the start node <strong>to (s,t)</strong>.</p> <p>So, for each <span class=arithmatex>\((s,t)\)</span> we only need to record the <strong>most probable path to (s,t)</strong> and can discard the non-winning node and its downstream nodes. Discarding the downstream nodes means that we will have fewer nodes to look at in the next timesteps, helping to keep the number of computations required relatively low.</p> <p>The animation below shows this. We start with all nodes in their original colors, and color nodes red if they represent the <strong>most probable path to (s,t)</strong>. When there is only one node in the graph that has a particular <span class=arithmatex>\((s,t)\)</span> value, it by default is the <strong>most probable path to (s,t)</strong>, so we color it red immediately. When there is more than one node with the same <span class=arithmatex>\((s,t)\)</span> value, we look at the cumulative probability (in light green) of these nodes. We mark the node with the lower cumulative probability dark blue, meaning we calculated its cumulative probability but realized that we can discard it. We mark its downstream nodes dark gray, to indicate that we can discard them, and don't need to consider them in future timesteps. Finally, for the node with the higher cumulative probability, we mark it red, to indicate that it is the <strong>most probable path to (s,t)</strong>.</p> <figure> <p><div class=video-container><video style="position: relative; width: 100%; height: 22.172vw" controls><source src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-redundancy_start_to_end.mp4 type=video/mp4></video></div> </p> <figcaption>We cycle through all possible (s,t) and discard the nodes that we do not need.</figcaption> </figure> <p>The cumulative product of the remaining node at the final timestep is the probability of the most likely alignment path. Again, we can trace back the steps from that node to the start to recover the exact path that gives that probability (<code>'CATTT'</code>).</p> <p>Although we show the cumulative probabilities for all nodes in the animation (for illustrative purposes), we didn't need to calculate the cumulative probabilities for any of the nodes that are dark gray, but we still managed to find the most likely path. We obtained the same result as with naive graph method but a lot fewer operations.</p> <h2 id=formalizing-the-efficient-forced-alignment-algorithm>Formalizing the efficient forced alignment algorithm<a class=headerlink href=#formalizing-the-efficient-forced-alignment-algorithm title="Permanent link">&para;</a></h2> <p>Let’s formalize the steps we followed. If we look at the nodes that we didn’t discard, they form a different shape of graph. The animation below transforms the tree graph into its new shape by hiding the discarded nodes behind the non-discarded nodes.</p> <figure> <p><div class=video-container><video style="position: relative; width: 100%; height: 22.172vw" controls><source src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-fold_viterbi.mp4 type=video/mp4></video></div> </p> <figcaption>We create a different shape of graph using only the nodes that we did not discard.</figcaption> </figure> <p>The resulting graph has a single node for each <span class=arithmatex>\((s,t)\)</span>. This graph is often referred to as a <strong>trellis</strong>. Each node has an associated number in red which is the <strong><em>probability</em> of the most likely path from start to <span class=arithmatex>\((s,t)\)</span></strong>. (We also keep the <span class=arithmatex>\(p(s,t)\)</span> values in dark green for illustrative purposes).</p> <p>We can recover the most likely alignment by looking at the node at <span class=arithmatex>\((S,T)\)</span>. Its cumulative probability, in red, is the probability of the most likely alignment. We can also recover the exact path that has that probability by tracing following the non-discarded edges (in light gray) backwards to the start token. This produces the <code>'CATTT'</code> sequences yet again.</p> <p>At each node <span class=arithmatex>\((s,t)\)</span>, the procedure we used to calculate the <strong>most probable path to <span class=arithmatex>\((s,t)\)</span></strong>, was to look at the tokens in the previous timestep that could have transitioned into this <span class=arithmatex>\((s,t)\)</span>, calculate the <em>candidates</em> for the <strong>most probable path to <span class=arithmatex>\((s,t)\)</span></strong>, and pick the maximum value.</p> <p>In our scenario, where at each timestep the token either stays the same or moves onto the next one, candidates come from <span class=arithmatex>\((s-1, t-1)\)</span> &amp; <span class=arithmatex>\((s,t-1)\)</span>. </p> <p>We can denote this formula as:</p> <p><code>prob-of-most-likely-path-to(s, t) = max (prob-of-most-likely-path-to(s-1, t-1) * p(s,t), prob-of-most-likely-path-to(s, t-1) * p(s,t))</code>.</p> <p>Let's make the formula shorter by denoting <code>prob-of-most-likely-path-to(s-1, t-1)</code> using the letter 'v' (to be explained later). So the formula becomes: </p> <div class=arithmatex>\[v(s, t) = \max (v(s-1, t-1) \times p(s,t), v(s, t-1) \times p(s,t))\]</div> <p>We can also show the rule on a subsection of our trellis graph, as below.</p> <figure> <p><img alt="Viterbi rule" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-viterbi_rule.png> </p> <figcaption>The formula we use to calculate v(s,t) probabilities in our current setup.</figcaption> </figure> <h2 id=the-viterbi-algorithm>The Viterbi algorithm<a class=headerlink href=#the-viterbi-algorithm title="Permanent link">&para;</a></h2> <p>What we described above is actually known as the Viterbi algorithm. What we denoted <code>prob-of-most-likely-path-to(s, t)</code> is often denoted <code>v(s,t)</code>, A.K.A. the Viterbi probability (of token <code>s</code> at time <code>t</code>).</p> <p>The Viterbi algorithm is an efficient method for finding the most likely alignment, and exploits the redundancies in the tree graph discussed above. It involves creating a matrix of size <span class=arithmatex>\(S \times T\)</span> (called a 'Viterbi matrix') and populating it column-by-column. </p> <p>The shape of the initialized Viterbi matrix for our scenario is shown below. Every element in the matrix corresponds to a node in the trellis (except for elements in the bottom left and top right of the matrix, which we did not draw in our trellis as they would not form valid alignments).</p> <table style='\"margin-left:' 0 !important;&quot;\> <tr> <th></th> <th>t=1</th> <th>t=2</th> <th>t=3</th> <th>t=4</th> <th>t=5</th> </tr> <tr> <td>s=0 AKA token is C</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> </tr> <tr> <td>s=1 AKA token is A</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> </tr> <tr> <td>s=2 AKA token is T</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> <td>??</td> </tr> </table> <p>We need to fill in every element in the Viterbi matrix column-by-column and row-by-row<sup id=fnref:row_by_row><a class=footnote-ref href=#fn:row_by_row>10</a></sup>. Once we have finished, <span class=arithmatex>\(v(s=S,t=T)\)</span> will contain the <em>probability of the most likely path to (S,T), i.e. from start to finish</em>, and if we recorded the argmax for computing each <span class=arithmatex>\((s,t)\)</span>, then we can use these values to recover what the exact sequence is which has this highest probability. The recorded argmaxes (which in our trellis look like light gray arrows) are often called "backpointers". The process of using the backpointers to recover the token sequence of the most likely alignment is known as "backtracking".</p> <p>Some special cases:</p> <ul> <li> <p>For the first <span class=arithmatex>\((t=1)\)</span> column of the Viterbi matrix, we set <span class=arithmatex>\(v(s=1,t=1)\)</span> to <span class=arithmatex>\(p(s=1,t=1)\)</span> and all other <span class=arithmatex>\(v(s&gt;1,t=1)\)</span> to 0. We do this because all possible alignments must start with the first token in the ground truth <span class=arithmatex>\((s=1)\)</span>. (This only holds for our current setup, and would be different in a CTC setup, see below).</p> </li> <li> <p>For some values of <span class=arithmatex>\((s,t)\)</span>, either the <span class=arithmatex>\((s-1, t-1)\)</span> or <span class=arithmatex>\((s, t-1)\)</span> nodes are not reachable, in which cases we ignore their terms in the <span class=arithmatex>\(v(s,t)\)</span> formula, and do a trivial max over one element.</p> </li> </ul> <h2 id=extending-to-ctc>Extending to CTC<a class=headerlink href=#extending-to-ctc title="Permanent link">&para;</a></h2> <p>The example above was simplified from a CTC approach to make it easier to understand and visualize. If you want to work with CTC alignments, you must allow blank tokens in between your ground truth tokens (the blank tokens are always optional except for in between repeated tokens.)</p> <p>Thus, if the reference text tokens are still <code>'C', 'A', 'T'</code>, we add optional 'blank' tokens in between them, which we denote as <code>&lt;b&gt;</code>. The diagram of the allowed sequence of tokens would look like this:</p> <figure> <p><img alt="Allowed sequence for CTC" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-allowed_seq_ctc.png> </p> <figcaption>Every possible alignment passes from "START" to "END" with T stops at each red token</figcaption> </figure> <p>As you can see, <code>S</code> — the total number of tokens — is 7 (3 non-blank tokens and 4 blank tokens). If we keep <span class=arithmatex>\(T=5\)</span>, the trellis for CTC with reference text tokens <code>'C', 'A', 'T'</code> would look like this:</p> <figure> <p><img alt="Trellis for CTC" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-ctc_trellis.png> </p> <figcaption>The shape of the trellis if we use a CTC model, our reference text tokens are 'C', 'A', 'T', and the number of timesteps in the ASR model output (T) is 5.</figcaption> </figure> <p>The Viterbi algorithm rules would also change, as follows:</p> <figure> <p><img alt="Viterbi rule for CTC" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-ctc_viterbi_rule.png> </p> <figcaption>The formula we use to calculate v(s,t) probabilities for a CTC model.</figcaption> </figure> <p>However, the principle remains the same: we initialize a Viterbi matrix of size <span class=arithmatex>\(S \times T\)</span> and fill it in according to the recursive formula. Once we fill it in, because there are 2 valid final tokens, we need to compare <span class=arithmatex>\(v(s=S-1,t=T)\)</span> and <span class=arithmatex>\(v(s=S,t=T)\)</span> - the token with the higher value is the end token of the most likely probability. To recover the overall most likely alignment, we need to backtrack from the higher of <span class=arithmatex>\(v(s=S-1,t=T)\)</span> or <span class=arithmatex>\(v(s=S,t=T)\)</span>.</p> <h2 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">&para;</a></h2> <p>In this tutorial, we have shown how to do forced alignment using the Viterbi algorithm, which is an efficient way to find the most likely path through the reference text tokens.</p> <p>You can obtain forced alignments using the <a href=https://github.com/NVIDIA/NeMo/tree/main/tools/nemo_forced_aligner>NeMo Forced Aligner (NFA)</a> tool within NeMo, which has an efficient PyTorch tensor-based <a href=https://github.com/NVIDIA/NeMo/blob/main/tools/nemo_forced_aligner/utils/viterbi_decoding.py>implementation</a> of Viterbi decoding on CTC models. An efficient CUDA-based implementation of Viterbi decoding was also recently <a href=https://pytorch.org/audio/main/generated/torchaudio.functional.forced_align.html#torchaudio.functional.forced_align>added</a> to TorchAudio, though it is currently only available in the nightly version of TorchAudio, and is not always faster than the current NFA PyTorch tensor-based implementation.</p> <p>Although our examples used characters are tokens, most NeMo models use sub-word tokens, such as in the diagram below. Furthermore, although we've given examples using probabilities ranging from 0 to 1, most Viterbi algorithms operate on log probabilities, which will make the operations in the algorithm more numerically stable. </p> <figure> <p><img alt="NFA pipeline" src=https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/nfa_forced_alignment_pipeline.png> </p> <figcaption>The NFA forced alignment pipeline, which has been described in this blog post.</figcaption> </figure> <p>To learn more about NFA, you can now refer to the resources <a href=../2023-08-nfa/ >here</a>.</p> <div class=footnote> <hr> <ol> <li id=fn:1> <p>Specifically we will be explaining how to use CTC-like (<a href=https://www.cs.toronto.edu/~graves/icml_2006.pdf>Connectionist Temporal Classification</a>) models which output a probability distribution over vocabulary tokens per audio timestep. We will explain how forced alignment works using a simplified CTC-like model, and explain how to extend it to a CTC model at the end of the tutorial. There are many CTC models <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/results.html#speech-recognition-languages>available</a> out of the box in NeMo. Alternative types of ASR models inlcude Transducer models (also <a href=https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/results.html#speech-recognition-languages>available</a> in NeMo), and attention-based encoder-decoder models (many of which build on this <a href=https://arxiv.org/pdf/1508.01211.pdf>work</a>, and a recent example of which is <a href=https://cdn.openai.com/papers/whisper.pdf>Whisper</a>). These types of models would require a different approach to obtaining forced alignments.&#160;<a class=footnote-backref href=#fnref:1 title="Jump back to footnote 1 in the text">&#8617;</a></p> </li> <li id=fn:butter_betty_bought> <p>This video is of an excerpt from 'The Jingle Book' by Carolyn Wells. The audio is a reading of a poem called "The Butter Betty Bought". The audio is taken from a <a href=https://www.archive.org/download/jingle_book_blb_librivox/jinglebook_03_wells.mp3>LibriVox recording</a> of the <a href=https://librivox.org/the-jingle-book-by-carolyn-wells/ >book</a>. We used NeMo Forced Aligner to generate the subtitle files for the video. The text was adapted from <a href=https://www.gutenberg.org/cache/epub/24560/pg24560.txt>Project Gutenberg</a>. Both the original audio and the text are in the public domain.&#160;<a class=footnote-backref href=#fnref:butter_betty_bought title="Jump back to footnote 2 in the text">&#8617;</a></p> </li> <li id=fn:2> <p>There are toolkits specialized for this purpose such as <a href=https://github.com/lumaku/ctc-segmentation>CTC Segmentation</a>, which has an <a href=https://github.com/NVIDIA/NeMo/tree/main/tools/ctc_segmentation>integration</a> in NeMo. It uses an extended version of the algorithm that we describe in this tutorial. The key difference is that the algorithm in this tutorial is <em>forced alignment</em> which assumes that the ground truth text provided is exactly what is spoken in the text. However, in practice the ground truth text may be different from what is spoken, and the algorithm in CTC Segmentation accounts for this.&#160;<a class=footnote-backref href=#fnref:2 title="Jump back to footnote 3 in the text">&#8617;</a></p> </li> <li id=fn:3> <p>These can be graphemes (i.e. letters or characters), phonemes, or subword-tokens&#160;<a class=footnote-backref href=#fnref:3 title="Jump back to footnote 4 in the text">&#8617;</a></p> </li> <li id=fn:5> <p>Such as <a href=https://github.com/lumaku/ctc-segmentation>CTC Segmentation</a> (also <a href=https://github.com/NVIDIA/NeMo/tree/main/tools/ctc_segmentation>integrated</a> in NeMo), <a href=https://github.com/lowerquality/gentle>Gentle</a> aligner.&#160;<a class=footnote-backref href=#fnref:5 title="Jump back to footnote 5 in the text">&#8617;</a></p> </li> <li id=fn:7> <p>If you want to learn more about how ASR models are trained, <a href=https://distill.pub/2017/ctc/ >this</a> is an excellent tutorial.&#160;<a class=footnote-backref href=#fnref:7 title="Jump back to footnote 6 in the text">&#8617;</a></p> </li> <li id=fn:greedy_path> <p>In the graph, we can also try to follow a 'greedy' path where we only take the outgoing path with the highest probability. In this example, this 'greedy' approach would give us the alignment path <code>CCATT</code>, which has a probability of 0.020 - lower than the actual most likely path.&#160;<a class=footnote-backref href=#fnref:greedy_path title="Jump back to footnote 7 in the text">&#8617;</a></p> </li> <li id=fn:tokens_timesteps> <p>To estimate the number of tokens, we assume there are 2 tokens per word <span class=arithmatex>\(\implies 10\)</span> words <span class=arithmatex>\(\times 2\)</span> tokens/word = 20 tokens. </p> <p>To estimate the number of timesteps, we assume a spectrogram frame hop size of 0.01 <span class=arithmatex>\(\implies \frac{5}{0.01} = 500 = T_{in} \implies {T} = \frac{T_{in}}{8} = \frac{500}{8} = 62.5 \approx 63\)</span>.&#160;<a class=footnote-backref href=#fnref:tokens_timesteps title="Jump back to footnote 8 in the text">&#8617;</a></p> </li> <li id=fn:stars_bars> <p>The exact number of possible paths in our formulation is equal to <span class=arithmatex>\({T-1 \choose S-1 }\)</span>, and if <span class=arithmatex>\(T=63\)</span> and <span class=arithmatex>\(S=20\)</span>, then <span class=arithmatex>\({T-1 \choose S-1 }={63-1 \choose 20-1 }={62 \choose 19 }=4.8 \times 10^{15}\)</span>.</p> <p>We will explain how we we deduced the formula <span class=arithmatex>\({T-1 \choose S-1 }\)</span> below.</p> <p>The number of possible paths is the same as the number of ways we could fit <span class=arithmatex>\(S\)</span> tokens into <span class=arithmatex>\(T\)</span> boxes, with the <span class=arithmatex>\(S\)</span> tokens being in some fixed order.</p> <p>This formulation is the same as having <span class=arithmatex>\(T\)</span> boxes, and putting <span class=arithmatex>\(S-1\)</span> markers in between the boxes, where the markers indicate a switch from one token to the next. There are <span class=arithmatex>\(T-1\)</span> locations where the markers can go (i.e. <span class=arithmatex>\(T-1\)</span> spaces between the boxes), therefore the number of possible ways we could arrange the markers is <span class=arithmatex>\({T-1 \choose S-1 }\)</span>. Therefore, this is also the number of possible alignment paths in our setup with <span class=arithmatex>\(S\)</span> tokens and <span class=arithmatex>\(T\)</span> timesteps.</p> <p>This is analogous to a known result in combinatorics called <a href=https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)#Theorem_one_proof>stars and bars</a> - in our case our 'boxes' are the 'stars' and our 'markers' are the 'bars'.&#160;<a class=footnote-backref href=#fnref:stars_bars title="Jump back to footnote 9 in the text">&#8617;</a></p> </li> <li id=fn:row_by_row> <p>Each entry within the same column is actually independent of the other entries in that column. We can compute those entries in any order or, even better, simultaneously - which would speed up the time to complete the algorithm.&#160;<a class=footnote-backref href=#fnref:row_by_row title="Jump back to footnote 10 in the text">&#8617;</a></p> </li> </ol> </div> <!-- Last update of source file --> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../2023-08-nfa/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Introducing NeMo Forced Aligner"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Introducing NeMo Forced Aligner </div> </div> </a> <a href=../2023-10-28-numba-fp16/ class="md-footer__link md-footer__link--next" aria-label="Next: Training NeMo RNN-T Models Efficiently with Numba FP16 Support"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Training NeMo RNN-T Models Efficiently with Numba FP16 Support </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2019 - 2023 NVIDIA </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/NVIDIA/NeMo target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.tabs.link", "content.tooltips", "navigation.expand", "navigation.indexes", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.footer", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.e1c3ead8.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>